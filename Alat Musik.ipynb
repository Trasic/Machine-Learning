{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import splitfolders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengambilan Folder Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '\\capstone\\Dataset'\n",
    "base_dir = '/capstone/Dataset'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1500 files [00:06, 249.17 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio(\n",
    "    base_dir,\n",
    "    output='fixDataset',\n",
    "    ratio=(.7,0.1, 0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angklung', 'Arumba', 'Calung', 'Jengglong', 'Kendang']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = 'fixDataset/train/'\n",
    "val_dir = 'fixDataset/val/'\n",
    "val_dir = 'fixDataset/test/'\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentasi Gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=0.45,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    brightness_range=(0.5,1.0), \n",
    "                    shear_range=0.2, \n",
    "                    zoom_range=(0.8,1.0), \n",
    "                    fill_mode='nearest', \n",
    "                    horizontal_flip=True\n",
    "                    )\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1198 images belonging to 5 classes.\n",
      "Found 304 images belonging to 5 classes.\n",
      "Found 304 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # direktori data train\n",
    "    target_size=(150,150), # mengubah resolusi seluruh gambar jadi 150*150\n",
    "    batch_size=32,# untuk menentukan jumlah image yang akan dimasukkan ke dalam steps training\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angklung', 'Arumba', 'Calung', 'Jengglong', 'Kendang']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    patience= 2,\n",
    "    verbose= 1,\n",
    "    factor=0.3,\n",
    "    min_lr=0.000001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "model = InceptionV3(weights = 'imagenet',\n",
    "                    include_top=False,\n",
    "                    input_shape=(150,150,3))\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 3, 3, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              18875392  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,335,589\n",
      "Trainable params: 19,532,805\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "add_model = Sequential()\n",
    "add_model.add(model)\n",
    "add_model.add(Flatten())\n",
    "add_model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "add_model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "add_model.add(Dropout(0.5))\n",
    "add_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model = add_model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "38/38 [==============================] - 89s 2s/step - loss: 0.7380 - accuracy: 0.7613 - val_loss: 0.0865 - val_accuracy: 0.9671 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "38/38 [==============================] - 92s 2s/step - loss: 0.1798 - accuracy: 0.9366 - val_loss: 0.0388 - val_accuracy: 0.9868 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "38/38 [==============================] - 92s 2s/step - loss: 0.1144 - accuracy: 0.9558 - val_loss: 0.0357 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "38/38 [==============================] - 78s 2s/step - loss: 0.0938 - accuracy: 0.9683 - val_loss: 0.0139 - val_accuracy: 0.9934 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "38/38 [==============================] - 102s 3s/step - loss: 0.0744 - accuracy: 0.9725 - val_loss: 0.0079 - val_accuracy: 0.9967 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "38/38 [==============================] - 81s 2s/step - loss: 0.1166 - accuracy: 0.9599 - val_loss: 0.0529 - val_accuracy: 0.9737 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9841\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "38/38 [==============================] - 73s 2s/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0051 - val_accuracy: 0.9967 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "38/38 [==============================] - 73s 2s/step - loss: 0.0378 - accuracy: 0.9841 - val_loss: 0.0094 - val_accuracy: 0.9967 - lr: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=15,\n",
    "                    shuffle=True,\n",
    "                    verbose=True,\n",
    "                    validation_data=val_generator,\n",
    "                    callbacks=[reduce_lr,monitor_val_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfile\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = askopenfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "var = input()\n",
    "Tk().withdraw()\n",
    "filepath = askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
